# -*- coding: utf-8 -*-
"""assignment3_[GregErikhman]_[GME2125].ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z5lcevMs9H6U8wRLj__7EdwMqyZHuXSL

<p align="center"><h1 align="center">QMSS5074GR <br> Projects in Advanced Machine Learning <br>Fall 2024 <br> FINAL PROJECT<br>Assignment 3 [GROUP Assignment]</h1>

---
<br>

#### (Change Unis in the title of your notebook. The format should be `assignment3_Part1_GRPID_UNI1_UNI2... UNIn.ipynb`)
#### **Your Unis** : Fill Here for all members (Comma separated).
#### **Your Full names** : Fill Here (in same order as UNIs)
#### **Link to your Public Github repository** : Fill here (single link is expected)

## **Stanford Sentiment Treebank - Movie Review Classification**

1.   List item
2.   List item



## Instructions for Part 1 (simple models):
1.   Get data in and set up X_train / X_test / y_train
2.   Preprocess data using Sklearn TFIDF Vectorizer/ Write and Save Preprocessor function
3. Fit model on preprocessed data and save preprocessor function and model
4. Generate predictions from X_test data

### 1. Get dataset in and set up training, validation and test data
"""

!git clone https://github.com/YJiangcm/SST-2-sentiment-analysis.git

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np
import warnings
warnings.simplefilter(action='ignore', category=Warning)

headers = ['sentiment', 'review']

train_df = pd.read_csv('SST-2-sentiment-analysis/data/train.tsv', sep='\t', names=headers)
val_df = pd.read_csv('SST-2-sentiment-analysis/data/dev.tsv', sep='\t', names=headers)
test_df = pd.read_csv('SST-2-sentiment-analysis/data/test.tsv', sep='\t', names=headers)

train_df.head()

X_train = train_df['review']
y_train = train_df['sentiment']

X_val = val_df['review']
y_val = val_df['sentiment']

X_test = test_df['review']
y_test = test_df['sentiment']

"""###2.   Preprocess data and Analyze

"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS

print("Number of stop words: {}".format(len(ENGLISH_STOP_WORDS)))
print("Every 10th stopword:\n{}".format(list(ENGLISH_STOP_WORDS)[::10]))

vectorizer = TfidfVectorizer(
    stop_words='english',
    max_df=0.9,
    min_df=5,
    max_features=10000
)

X_train_tfidf = vectorizer.fit_transform(X_train)

X_val_tfidf = vectorizer.transform(X_val)
X_test_tfidf = vectorizer.transform(X_test)

feature_names = vectorizer.get_feature_names_out()
print("Shape of the training DTM:", X_train_tfidf.shape)
print("Example feature names:", feature_names[:10])

vectorizer.fit(X_train)

def preprocessor(data):
    return vectorizer.transform(data)

X_train_tfidf = preprocessor(X_train)
X_test_tfidf = preprocessor(X_test)

print("Shape of training DTM:", X_train_tfidf.shape)
print("Shape of test DTM:", X_test_tfidf.shape)

"""Perform EDA and Visualizations (class balance, review lengths, word frequency per class, Wordcloud, etc)"""

import matplotlib.pyplot as plt
import seaborn as sns

class_counts = y_train.value_counts()

plt.figure(figsize=(8, 6))
sns.barplot(x=class_counts.index, y=class_counts.values)
plt.title("Class Balance")
plt.xlabel("Class")
plt.ylabel("Count")
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from wordcloud import WordCloud
import pandas as pd
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

class_counts = y_train.value_counts()
plt.figure(figsize=(10, 20))
plt.subplot(4, 1, 1)
sns.barplot(x=class_counts.index, y=class_counts.values)
plt.title("Class Balance")
plt.xlabel("Class")
plt.ylabel("Count")

review_lengths = X_train_tfidf.sum(axis=1).A1
plt.subplot(4, 1, 2)
sns.histplot(review_lengths, bins=30, kde=True)
plt.title("Review Length Distribution (TF-IDF Preprocessed)")
plt.xlabel("Non-zero TF-IDF Terms (per review)")
plt.ylabel("Frequency")

class_0_indices = y_train[y_train == 0].index
class_1_indices = y_train[y_train == 1].index

class_0_matrix = X_train_tfidf[class_0_indices, :]
class_1_matrix = X_train_tfidf[class_1_indices, :]

class_0_word_counts = class_0_matrix.sum(axis=0).A1
class_1_word_counts = class_1_matrix.sum(axis=0).A1

top_class_0 = pd.DataFrame({
    'Word': vectorizer.get_feature_names_out(),
    'Frequency': class_0_word_counts
}).nlargest(20, 'Frequency')

top_class_1 = pd.DataFrame({
    'Word': vectorizer.get_feature_names_out(),
    'Frequency': class_1_word_counts
}).nlargest(20, 'Frequency')

plt.subplot(4, 1, 3)
sns.barplot(x='Frequency', y='Word', data=top_class_0, color='blue')
plt.title("Top 20 Words in Class 0 (TF-IDF)")

plt.subplot(4, 1, 4)
sns.barplot(x='Frequency', y='Word', data=top_class_1, color='orange')
plt.title("Top 20 Words in Class 1 (TF-IDF)")

plt.tight_layout()
plt.show()

wordcloud_0 = WordCloud(
    width=800, height=400, max_words=100, background_color='white',
    stopwords=ENGLISH_STOP_WORDS
).generate_from_frequencies(dict(zip(vectorizer.get_feature_names_out(), class_0_word_counts)))

wordcloud_1 = WordCloud(
    width=800, height=400, max_words=100, background_color='white',
    stopwords=ENGLISH_STOP_WORDS
).generate_from_frequencies(dict(zip(vectorizer.get_feature_names_out(), class_1_word_counts)))

plt.figure(figsize=(14, 7))
plt.subplot(1, 2, 1)
plt.imshow(wordcloud_0, interpolation='bilinear')
plt.axis('off')
plt.title("Word Cloud for Class 0 (TF-IDF)")

plt.subplot(1, 2, 2)
plt.imshow(wordcloud_1, interpolation='bilinear')
plt.axis('off')
plt.title("Word Cloud for Class 1 (TF-IDF)")

plt.tight_layout()
plt.show()

"""If you think lemmatization, stemming and other text preprocessing should be performed, code here. You can also go back and include it in the preprocessing function if you want.

You are also free to include any extra features that you extract from the text to aid in modeling (Optional)

###3. Fit model on preprocessed data
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
rf_model = RandomForestClassifier(random_state=42, n_estimators=100)

rf_model.fit(X_train_tfidf, y_train)

y_pred = rf_model.predict(X_test_tfidf)

accuracy = accuracy_score(y_test, y_pred)

print("Random Forest Model Accuracy: {:.2f}%".format(accuracy * 100))

print("\nClassification Report:\n")
print(classification_report(y_test, y_pred))

"""### 5. Repeat the above process with different models

"""

from sklearn.svm import SVC

svm_model = SVC(kernel='linear', C=1, random_state=42)

svm_model.fit(X_train_tfidf, y_train)

y_pred_svm = svm_model.predict(X_test_tfidf)

svm_accuracy = accuracy_score(y_test, y_pred_svm)

print("SVM Model Accuracy: {:.2f}%".format(svm_accuracy * 100))

print("\nClassification Report:\n")
print(classification_report(y_test, y_pred_svm))

from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from nltk.stem import WordNetLemmatizer
import nltk
nltk.download('wordnet')
nltk.download('omw-1.4')

lemmatizer = WordNetLemmatizer()

def lemmatize_text(text):
    return " ".join([lemmatizer.lemmatize(word) for word in text.split()])

X_train_lemmatized = X_train.apply(lemmatize_text)
X_test_lemmatized = X_test.apply(lemmatize_text)

vectorizer.fit(X_train_lemmatized)
X_train_tfidf = vectorizer.transform(X_train_lemmatized)
X_test_tfidf = vectorizer.transform(X_test_lemmatized)

param_grid_rf = {
  'n_estimators': [50, 100],
    'max_depth': [10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

rf_model = RandomForestClassifier(random_state=42)

random_search_rf = RandomizedSearchCV(
    estimator=rf_model,
    param_distributions=param_grid_rf,
    n_iter=50,
    cv=3,
    verbose=2,
    n_jobs=-1,
    random_state=42
)

random_search_rf.fit(X_train_tfidf, y_train)

print("Best Model Parameters:", random_search_rf.best_params_)
print("Best Cross-Validation Score: {:.2f}%".format(random_search_rf.best_score_ * 100))

best_rf_model = random_search_rf.best_estimator_
y_pred_rf = best_rf_model.predict(X_test_tfidf)

test_accuracy_rf = accuracy_score(y_test, y_pred_rf)
print("Test Accuracy with Best Model: {:.2f}%".format(test_accuracy_rf * 100))

print("\nClassification Report:\n")
print(classification_report(y_test, y_pred_rf))

from sklearn.neighbors import KNeighborsClassifier

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train_tfidf, y_train)

y_pred_knn = knn_model.predict(X_test_tfidf)

test_accuracy_knn = accuracy_score(y_test, y_pred_knn)
print("Test Accuracy with KNN Model: {:.2f}%".format(test_accuracy_knn * 100))

print("\nClassification Report:\n")
print(classification_report(y_test, y_pred_knn))

print("\nClassification Report SVM:\n")
print(classification_report(y_test, y_pred_svm))

print("\nClassification Report KNN:\n")
print(classification_report(y_test, y_pred_knn))

print("\nClassification Report GridSearch + RF:\n")
print(classification_report(y_test, y_pred_rf))

print("\nClassification Report RF:\n")
print(classification_report(y_test, y_pred))

"""### Discuss which models performed better and why?

Out of the four models implemented the order in which they performed is as follows : SVM, Random Forest, GridSearch, and KNN. This makes sense as some models are too complex and required simplification to process in Colab (Gridsearch), while others (KNN) are not sufficiently complex to learn on the complex text data.

## Instructions for Part 2 (neural networks):
1.   Get data in and set up X_train / X_test / y_train
2.   Preprocess data using keras Tokenizer
3. Fit model on preprocessed data
4. Generate predictions from X_test data

###1.   Load Data
"""

import pandas as pd
import warnings
warnings.simplefilter(action='ignore', category=Warning)

X_train = train_df['review']
y_train = train_df['sentiment']

X_val = val_df['review']
y_val = val_df['sentiment']

X_test = test_df['review']
y_test = test_df['sentiment']

X_train.head()

"""###2.   Preprocess data using keras tokenizer

"""

import pandas as pd
import warnings
warnings.simplefilter(action='ignore', category=Warning)

from tensorflow import keras
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np

X_train = train_df['review']
y_train = train_df['sentiment']

X_val = val_df['review']
y_val = val_df['sentiment']

X_test = test_df['review']
y_test = test_df['sentiment']

tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

def preprocessor(data):
    sequences = tokenizer.texts_to_sequences(data)
    padded = pad_sequences(sequences, maxlen=100, padding='post', truncating='post')
    return padded

X_train_padded = preprocessor(X_train)
X_test_padded = preprocessor(X_test)

"""###3. Fit model on preprocessed data

"""

from tensorflow import keras
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Dense, Embedding, Flatten
from tensorflow.keras.models import Sequential
import numpy as np

X_train = train_df['review']
y_train = train_df['sentiment']

X_val = val_df['review']
y_val = val_df['sentiment']

X_test = test_df['review']
y_test = test_df['sentiment']

tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

def preprocessor(data):
    sequences = tokenizer.texts_to_sequences(data)
    padded = pad_sequences(sequences, maxlen=100, padding='post', truncating='post')
    return padded

X_train_padded = preprocessor(X_train)
X_val_padded = preprocessor(X_val)
X_test_padded = preprocessor(X_test)

model = Sequential([
    Embedding(input_dim=10000, output_dim=16, input_length=100),
    Flatten(),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.fit(X_train_padded, y_train, epochs=5, validation_data=(X_val_padded, y_val), batch_size=32)

print(X_train_padded.shape)
print(X_test_padded.shape)

history = model.fit(
    X_train_padded, y_train,
    epochs=5,
    validation_data=(X_val_padded, y_val),
    batch_size=32
)

plt.figure(figsize=(12, 6))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""### 4. Generate predictions from X_test data and calculate accuracy



"""

y_pred = model.predict(X_test_padded)
y_pred = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy:.2f}")

"""### 5. Experiment with more models

"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, BatchNormalization
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score

model = Sequential([
    Embedding(input_dim=10000, output_dim=128, input_length=100),
    LSTM(128, return_sequences=True),
    BatchNormalization(),
    Dropout(0.3),
    LSTM(64, return_sequences=True),
    BatchNormalization(),
    Dropout(0.3),
    LSTM(32),
    BatchNormalization(),
    Dropout(0.3),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(
    X_train_padded, y_train,
    epochs=5,
    validation_data=(X_val_padded, y_val),
    batch_size=32
)

plt.figure(figsize=(12, 6))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

y_pred = model.predict(X_test_padded)
y_pred = (y_pred > 0.5).astype(int)
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy:.2f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('LSTM Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('LSTM Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""Does your model perform better or worse than your prior deep learning model? Why might that be the case?

A LTSM model may not be the correct methodology despite how it is modified. It is simply overkill for the simple task, and a simplier model may be more effective. At the same time LTSM is sequential in nature which will make it slow and hard to modify iteratively.

### 6. Tune model within range of hyperparameters with Keras Tuner

*Consult [documentation](https://keras.io/guides/keras_tuner/getting_started/) to see full functionality.*
"""

! pip install keras_tuner

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout
import keras_tuner as kt
import matplotlib.pyplot as plt

def build_model(hp):
    model = Sequential()
    model.add(Embedding(input_dim=10000,
                        output_dim=hp.Int('embedding_dim', min_value=64, max_value=256, step=64),
                        input_length=100))

    for i in range(hp.Int('num_lstm_layers', 1, 3)):
        model.add(LSTM(units=hp.Int(f'lstm_units_{i}', min_value=32, max_value=128, step=32),
                       return_sequences=(i < hp.Int('num_lstm_layers', 1, 3) - 1)))
        model.add(Dropout(hp.Float(f'dropout_{i}', min_value=0.2, max_value=0.5, step=0.1)))

    model.add(Dense(1, activation='sigmoid'))

    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

tuner = kt.RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=5,
    directory='tuning_directory',
    project_name='lstm_tuning'
)

tuner.search(X_train_padded, y_train,
             epochs=5,
             validation_data=(X_val_padded, y_val),
             batch_size=128)

best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(f"Best embedding dimension: {best_hps.get('embedding_dim')}")
print(f"Number of LSTM layers: {best_hps.get('num_lstm_layers')}")
print(f"Learning rate: {best_hps.get('learning_rate')}")

best_model = tuner.hypermodel.build(best_hps)

history = best_model.fit(
    X_train_padded, y_train,
    epochs=5,
    validation_data=(X_val_padded, y_val),
    batch_size=128
)

plt.figure(figsize=(12, 6))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Best Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Best Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

print(f"Best embedding dimension: {best_hps.get('embedding_dim')}")
print(f"Number of LSTM layers: {best_hps.get('num_lstm_layers')}")
for i in range(best_hps.get('num_lstm_layers')):
    print(f"Best LSTM units for layer {i}: {best_hps.get(f'lstm_units_{i}')}")
    print(f"Best dropout for layer {i}: {best_hps.get(f'dropout_{i}')}")
print(f"Best learning rate: {best_hps.get('learning_rate')}")

best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

def build_best_model(best_hps):
    model = Sequential()
    model.add(Embedding(input_dim=10000,
                        output_dim=best_hps.get('embedding_dim'),
                        input_length=100))
    for i in range(best_hps.get('num_lstm_layers')):
        model.add(LSTM(units=best_hps.get(f'lstm_units_{i}'),
                       return_sequences=(i < best_hps.get('num_lstm_layers') - 1)))
        model.add(Dropout(best_hps.get(f'dropout_{i}')))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=best_hps.get('learning_rate')),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

X_combined = np.concatenate((X_train_padded, X_val_padded), axis=0)
y_combined = np.concatenate((y_train, y_val), axis=0)

best_model = build_best_model(best_hps)

history = best_model.fit(
    X_combined, y_combined,
    epochs=5,
    batch_size=128
)

test_loss, test_accuracy = best_model.evaluate(X_test_padded, y_test)
print(f"Test Accuracy: {test_accuracy:.2f}")

plt.figure(figsize=(12, 6))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.title('Best Model Accuracy (Full Dataset)')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.title('Best Model Loss (Full Dataset)')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

best_hps = tuner.get_best_hyperparameters(num_trials=2)
for i, hp in enumerate(best_hps):
    print(f"Trial {i+1}:")
    print(hp.values)

"""What were the best hyperparameters found? Why might that be performing better than others?

The best hyperparmeters are as following.

LTSM 96 : Allows for better learning of the complex patterns required for linguistic analysis

Dropout 0.4 : Better regularization avoids overfitting

Learning Rate 0.001 : A minimized learning rate is optimal for the model adjusting throughout its learning, especially due to its complexity.

## 3 more models

Train three more prediction models to try to predict the SST sentiment
dataset well.

○ Use Conv1d layers in first model

○ Use Transfer learning with Glove Embeddings for 2nd model

○ Third model can be any Transfer learning model of your choice (Transformer architecture required, eg. BERT and related)
"""

#MODEL 1
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense

conv_model = Sequential([
    Embedding(input_dim=10000, output_dim=128, input_length=100),
    Conv1D(filters=64, kernel_size=3, activation='relu'),
    MaxPooling1D(pool_size=2),
    Flatten(),
    Dense(1, activation='sigmoid')
])

conv_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
conv_model.fit(X_train_padded, y_train, epochs=5, batch_size=32, validation_data=(X_val_padded, y_val))

feature_extractor = Sequential(conv_model.layers[:-1])
X_train_features = feature_extractor.predict(X_train_padded)
X_val_features = feature_extractor.predict(X_val_padded)
X_test_features = feature_extractor.predict(X_test_padded)

from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear', C=1))
svm_model.fit(X_train_features, y_train)

y_pred_model1 = svm_model.predict(X_test_features)
accuracy_model1 = accuracy_score(y_test, y_pred_model1)
print(f"Test Accuracy for MODEL 1 (Conv1D + SVM): {accuracy_model1:.2f}")

print("\nClassification Report for MODEL 1 (Conv1D + SVM):\n")
print(classification_report(y_test, y_pred_model1))

!rm -f glove.6B.zip glove.6B.100d.txt

!wget --no-check-certificate https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip
!unzip -q glove.6B.zip

#MODEL 2
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.metrics import accuracy_score

def load_glove_embeddings(glove_file, embedding_dim=100):
    embeddings_index = {}
    with open(glove_file, encoding="utf-8") as f:
        for line in f:
            values = line.split()
            word = values[0]
            vector = np.asarray(values[1:], dtype="float32")
            embeddings_index[word] = vector
    return embeddings_index

def create_embedding_matrix(tokenizer, embeddings_index, embedding_dim):
    num_words = min(len(tokenizer.word_index) + 1, 10000)
    embedding_matrix = np.zeros((num_words, embedding_dim))
    for word, i in tokenizer.word_index.items():
        if i >= 10000:
            continue
        embedding_vector = embeddings_index.get(word)
        if embedding_vector is not None:
            embedding_matrix[i] = embedding_vector
    return embedding_matrix

def extract_glove_features(X_seq, embedding_matrix):
    embeddings = np.zeros((X_seq.shape[0], embedding_matrix.shape[1]))
    for i, seq in enumerate(X_seq):
        valid_embeddings = [embedding_matrix[word_idx] for word_idx in seq if word_idx != 0]
        if valid_embeddings:
            embeddings[i] = np.mean(valid_embeddings, axis=0)
    return embeddings

tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=100)
X_val_seq = pad_sequences(tokenizer.texts_to_sequences(X_val), maxlen=100)
X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=100)

glove_file = 'glove.6B.100d.txt'
embedding_dim = 100
embeddings_index = load_glove_embeddings(glove_file, embedding_dim)

embedding_matrix = create_embedding_matrix(tokenizer, embeddings_index, embedding_dim)

X_train_glove = extract_glove_features(X_train_seq, embedding_matrix)
X_val_glove = extract_glove_features(X_val_seq, embedding_matrix)
X_test_glove = extract_glove_features(X_test_seq, embedding_matrix)

svm_model_glove = make_pipeline(StandardScaler(), SVC(kernel='linear', C=1))
svm_model_glove.fit(X_train_glove, y_train)

y_pred_model2 = svm_model_glove.predict(X_test_glove)
accuracy_model2 = accuracy_score(y_test, y_pred_model2)
print(f"Test Accuracy for MODEL 2 (GloVe + SVM): {accuracy_model2:.2f}")

print("\nClassification Report for MODEL 2 (GloVe + SVM):\n")
print(classification_report(y_test, y_pred_model2))

!pip install transformers datasets
!pip install torch

from transformers import BertTokenizer, BertForSequenceClassification
from transformers import Trainer, TrainingArguments
from datasets import Dataset
import torch

#MODEL 3
from transformers import DistilBertTokenizer, DistilBertModel
from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import torch
import numpy as np
import pandas as pd
import time

model_name = "distilbert-base-uncased"
tokenizer = DistilBertTokenizer.from_pretrained(model_name)
bert_model = DistilBertModel.from_pretrained(model_name)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
bert_model.to(device)

def prepare_text_data(data):
    if isinstance(data, pd.Series):
        data = data.fillna("").astype(str).tolist()
    elif isinstance(data, list):
        data = [str(x) if x is not None else "" for x in data]
    else:
        raise ValueError("Input data must be a Pandas Series or a List of strings.")
    return data

X_train = prepare_text_data(X_train)
X_val = prepare_text_data(X_val)
X_test = prepare_text_data(X_test)

def extract_bert_embeddings_batch(texts, tokenizer, model, batch_size=64, max_length=64):
    model.eval()
    embeddings = []
    with torch.no_grad():
        for i in range(0, len(texts), batch_size):
            start_time = time.time()
            batch_texts = texts[i:i + batch_size]
            tokens = tokenizer(
                batch_texts,
                padding="max_length",
                truncation=True,
                max_length=max_length,
                return_tensors="pt"
            ).to(device)
            output = model(**tokens)
            cls_embeddings = output.last_hidden_state[:, 0, :]
            embeddings.append(cls_embeddings.cpu().numpy())
            end_time = time.time()
            print(f"Processed batch {i // batch_size + 1}/{len(texts) // batch_size + 1} "
                  f"in {end_time - start_time:.2f} seconds.")
    return np.vstack(embeddings)

X_train_bert = extract_bert_embeddings_batch(X_train, tokenizer, bert_model, batch_size=64, max_length=64)
X_val_bert = extract_bert_embeddings_batch(X_val, tokenizer, bert_model, batch_size=64, max_length=64)
X_test_bert = extract_bert_embeddings_batch(X_test, tokenizer, bert_model, batch_size=64, max_length=64)

svm_model_bert = make_pipeline(StandardScaler(), SVC(kernel='linear', C=1))
svm_model_bert.fit(X_train_bert, y_train)

y_pred_model3 = svm_model_bert.predict(X_test_bert)
accuracy_model3 = accuracy_score(y_test, y_pred_model3)
print(f"Test Accuracy for MODEL 3 (DistilBERT + SVM): {accuracy_model3:.2f}")

print("\nClassification Report for MODEL 3 (DistilBERT + SVM):\n")
print(classification_report(y_test, y_pred_model3))

"""Tabularize results from ALL your models in this notebook and compare performance"""

# Consolidated Classification Report Summary
print("\n--- Final Model Comparison ---\n")

print("\nClassification Report MODEL 1 (Conv1D + SVM):\n")
print(classification_report(y_test, y_pred_model1))

print("\nClassification Report MODEL 2 (GloVe + SVM):\n")
print(classification_report(y_test, y_pred_model2))

print("\nClassification Report MODEL 3 (DistilBERT + SVM):\n")
print(classification_report(y_test, y_pred_model3))
print("\nClassification Report SVM:\n")
print(classification_report(y_test, y_pred_svm))

print("\nClassification Report KNN:\n")
print(classification_report(y_test, y_pred_knn))

print("\nClassification Report GridSearch + RF:\n")
print(classification_report(y_test, y_pred_rf))

print("\nClassification Report RF:\n")
print(classification_report(y_test, y_pred))

"""Results Discussion : Point out why specific models may have performed better than others. and discuss failures if any."""

# As discussed in previous cells, the worst performing models were not intended for the binary text classification for this project. The most effective SVM model utilizing BERT Tokenization demonstrates that with significantly higher accuracy than any other model, and outperforming less effective models by about 30% on pure accuracy.